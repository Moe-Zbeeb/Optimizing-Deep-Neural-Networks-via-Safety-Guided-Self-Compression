{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the words\n",
    "words = open('/home/mohammad/Safety-Driven-Self-Compressing-Neural-Networks/Neural Probablistic /data/names.txt', 'r').read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}  # Start indices from 1\n",
    "stoi['.'] = 0  # End-of-sequence token\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(stoi)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: torch.Size([182625, 3]), torch.Size([182625])\n",
      "Validation set size: torch.Size([22655, 3]), torch.Size([22655])\n",
      "Test set size: torch.Size([22866, 3]), torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words, block_size=3):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size  # Initialize context with zeros (start tokens)\n",
    "        for ch in w + '.':  # Append the end-of-sequence token\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]  # Slide the context window\n",
    "    return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "block_size = 3  # Context size\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1], block_size)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], block_size)\n",
    "Xte, Yte = build_dataset(words[n2:], block_size)\n",
    "\n",
    "print(f\"Training set size: {Xtr.shape}, {Ytr.shape}\")\n",
    "print(f\"Validation set size: {Xdev.shape}, {Ydev.shape}\")\n",
    "print(f\"Test set size: {Xte.shape}, {Yte.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11897\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_neurons = 200\n",
    "\n",
    "C = torch.randn((vocab_size, embedding_dim), generator=g)\n",
    "W1 = torch.randn((block_size * embedding_dim, hidden_neurons), generator=g)\n",
    "b1 = torch.randn(hidden_neurons, generator=g)\n",
    "W2 = torch.randn((hidden_neurons, vocab_size), generator=g)\n",
    "b2 = torch.randn(vocab_size, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "print(f\"Total parameters: {sum(p.numel() for p in parameters)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Preservation Set: ['jp', 'jb', 'kc', 'kc', 'kj']\n"
     ]
    }
   ],
   "source": [
    "# Load preservation set from a text file\n",
    "def load_preservation_set(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        preservation_words = [line.strip().lower() for line in f.readlines()]\n",
    "    return preservation_words\n",
    "\n",
    "preservation_file_path = '/home/mohammad/Safety-Driven-Self-Compressing-Neural-Networks/Neural Probablistic /data/hardest_examples.txt'\n",
    "preservation_words = load_preservation_set(preservation_file_path)\n",
    "\n",
    "# Build dataset for preservation set\n",
    "Xpres, Ypres = build_dataset(preservation_words, block_size)\n",
    "preservation_set = (Xpres, Ypres)\n",
    "\n",
    "print(f\"Loaded Preservation Set: {preservation_words[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preservation_set(preservation_set, parameters):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    Xpres, Ypres = preservation_set\n",
    "    with torch.no_grad():\n",
    "        emb = C[Xpres]\n",
    "        h = torch.tanh(emb.view(-1, W1.shape[0]) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Ypres)\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_neurons(W1, W2, compression_rate=0.1):\n",
    "    num_neurons_w1 = W1.shape[1]\n",
    "    num_neurons_w2 = W2.shape[0]\n",
    "    \n",
    "    # Number of neurons to compress\n",
    "    num_compress_w1 = int(compression_rate * num_neurons_w1)\n",
    "    num_compress_w2 = int(compression_rate * num_neurons_w2)\n",
    "    \n",
    "    # Randomly select neurons to compress\n",
    "    compressed_neurons_w1 = random.sample(range(num_neurons_w1), num_compress_w1)\n",
    "    compressed_neurons_w2 = random.sample(range(num_neurons_w2), num_compress_w2)\n",
    "    \n",
    "    # Backup original weights\n",
    "    W1_backup = W1.data[:, compressed_neurons_w1].clone()\n",
    "    W2_backup = W2.data[compressed_neurons_w2, :].clone()\n",
    "    \n",
    "    # Zero out the selected neurons\n",
    "    W1.data[:, compressed_neurons_w1] = 0\n",
    "    W2.data[compressed_neurons_w2, :] = 0\n",
    "    \n",
    "    return W1_backup, W2_backup, compressed_neurons_w1, compressed_neurons_w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_neurons(W1, W2, W1_backup, W2_backup, compressed_neurons_w1, compressed_neurons_w2):\n",
    "    W1.data[:, compressed_neurons_w1] = W1_backup\n",
    "    W2.data[compressed_neurons_w2, :] = W2_backup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Training Loss: 23.739702224731445\n",
      "Step 1000: Restored neurons due to increased preservation loss.\n",
      "Step 2000: Restored neurons due to increased preservation loss.\n",
      "Step 3000: Restored neurons due to increased preservation loss.\n",
      "Step 4000: Restored neurons due to increased preservation loss.\n",
      "Step 5000: Restored neurons due to increased preservation loss.\n",
      "Step 6000: Restored neurons due to increased preservation loss.\n",
      "Step 7000: Restored neurons due to increased preservation loss.\n",
      "Step 8000: Restored neurons due to increased preservation loss.\n",
      "Step 9000: Restored neurons due to increased preservation loss.\n",
      "Step 10000: Restored neurons due to increased preservation loss.\n",
      "Step 10000, Training Loss: 2.071927785873413\n",
      "Step 11000: Restored neurons due to increased preservation loss.\n",
      "Step 12000: Restored neurons due to increased preservation loss.\n",
      "Step 13000: Restored neurons due to increased preservation loss.\n",
      "Step 14000: Restored neurons due to increased preservation loss.\n",
      "Step 15000: Restored neurons due to increased preservation loss.\n",
      "Step 16000: Restored neurons due to increased preservation loss.\n",
      "Step 17000: Restored neurons due to increased preservation loss.\n",
      "Step 18000: Restored neurons due to increased preservation loss.\n",
      "Step 19000: Restored neurons due to increased preservation loss.\n",
      "Step 20000: Restored neurons due to increased preservation loss.\n",
      "Step 20000, Training Loss: 2.320997953414917\n",
      "Step 21000: Restored neurons due to increased preservation loss.\n",
      "Step 22000: Restored neurons due to increased preservation loss.\n",
      "Step 23000: Restored neurons due to increased preservation loss.\n",
      "Step 24000: Restored neurons due to increased preservation loss.\n",
      "Step 25000: Restored neurons due to increased preservation loss.\n",
      "Step 26000: Restored neurons due to increased preservation loss.\n",
      "Step 27000: Restored neurons due to increased preservation loss.\n",
      "Step 28000: Restored neurons due to increased preservation loss.\n",
      "Step 29000: Restored neurons due to increased preservation loss.\n",
      "Step 30000: Restored neurons due to increased preservation loss.\n",
      "Step 30000, Training Loss: 2.1845011711120605\n",
      "Step 31000: Restored neurons due to increased preservation loss.\n",
      "Step 32000: Restored neurons due to increased preservation loss.\n",
      "Step 33000: Restored neurons due to increased preservation loss.\n",
      "Step 34000: Restored neurons due to increased preservation loss.\n",
      "Step 35000: Restored neurons due to increased preservation loss.\n",
      "Step 36000: Restored neurons due to increased preservation loss.\n",
      "Step 37000: Restored neurons due to increased preservation loss.\n",
      "Step 38000: Restored neurons due to increased preservation loss.\n",
      "Step 39000: Restored neurons due to increased preservation loss.\n",
      "Step 40000: Restored neurons due to increased preservation loss.\n",
      "Step 40000, Training Loss: 2.078101634979248\n",
      "Step 41000: Restored neurons due to increased preservation loss.\n",
      "Step 42000: Restored neurons due to increased preservation loss.\n",
      "Step 43000: Restored neurons due to increased preservation loss.\n",
      "Step 44000: Restored neurons due to increased preservation loss.\n",
      "Step 45000: Restored neurons due to increased preservation loss.\n",
      "Step 46000: Restored neurons due to increased preservation loss.\n",
      "Step 47000: Restored neurons due to increased preservation loss.\n",
      "Step 48000: Restored neurons due to increased preservation loss.\n",
      "Step 49000: Restored neurons due to increased preservation loss.\n",
      "Step 50000: Restored neurons due to increased preservation loss.\n",
      "Step 50000, Training Loss: 2.166442394256592\n",
      "Step 51000: Restored neurons due to increased preservation loss.\n",
      "Step 52000: Restored neurons due to increased preservation loss.\n",
      "Step 53000: Restored neurons due to increased preservation loss.\n",
      "Step 54000: Restored neurons due to increased preservation loss.\n",
      "Step 55000: Restored neurons due to increased preservation loss.\n",
      "Step 56000: Restored neurons due to increased preservation loss.\n",
      "Step 57000: Restored neurons due to increased preservation loss.\n",
      "Step 58000: Restored neurons due to increased preservation loss.\n",
      "Step 59000: Restored neurons due to increased preservation loss.\n",
      "Step 60000: Restored neurons due to increased preservation loss.\n",
      "Step 60000, Training Loss: 2.6756954193115234\n",
      "Step 61000: Restored neurons due to increased preservation loss.\n",
      "Step 62000: Restored neurons due to increased preservation loss.\n",
      "Step 63000: Restored neurons due to increased preservation loss.\n",
      "Step 64000: Restored neurons due to increased preservation loss.\n",
      "Step 65000: Restored neurons due to increased preservation loss.\n",
      "Step 66000: Restored neurons due to increased preservation loss.\n",
      "Step 67000: Restored neurons due to increased preservation loss.\n",
      "Step 68000: Restored neurons due to increased preservation loss.\n",
      "Step 69000: Restored neurons due to increased preservation loss.\n",
      "Step 70000: Restored neurons due to increased preservation loss.\n",
      "Step 70000, Training Loss: 1.6751562356948853\n",
      "Step 71000: Restored neurons due to increased preservation loss.\n",
      "Step 72000: Restored neurons due to increased preservation loss.\n",
      "Step 73000: Restored neurons due to increased preservation loss.\n",
      "Step 74000: Restored neurons due to increased preservation loss.\n",
      "Step 75000: Restored neurons due to increased preservation loss.\n",
      "Step 76000: Restored neurons due to increased preservation loss.\n",
      "Step 77000: Restored neurons due to increased preservation loss.\n",
      "Step 78000: Restored neurons due to increased preservation loss.\n",
      "Step 79000: Restored neurons due to increased preservation loss.\n",
      "Step 80000: Restored neurons due to increased preservation loss.\n",
      "Step 80000, Training Loss: 2.4762847423553467\n",
      "Step 81000: Restored neurons due to increased preservation loss.\n",
      "Step 82000: Restored neurons due to increased preservation loss.\n",
      "Step 83000: Restored neurons due to increased preservation loss.\n",
      "Step 84000: Restored neurons due to increased preservation loss.\n",
      "Step 85000: Restored neurons due to increased preservation loss.\n",
      "Step 86000: Restored neurons due to increased preservation loss.\n",
      "Step 87000: Restored neurons due to increased preservation loss.\n",
      "Step 88000: Restored neurons due to increased preservation loss.\n",
      "Step 89000: Restored neurons due to increased preservation loss.\n",
      "Step 90000: Restored neurons due to increased preservation loss.\n",
      "Step 90000, Training Loss: 2.649089813232422\n",
      "Step 91000: Restored neurons due to increased preservation loss.\n",
      "Step 92000: Restored neurons due to increased preservation loss.\n",
      "Step 93000: Restored neurons due to increased preservation loss.\n",
      "Step 94000: Restored neurons due to increased preservation loss.\n",
      "Step 95000: Restored neurons due to increased preservation loss.\n",
      "Step 96000: Restored neurons due to increased preservation loss.\n",
      "Step 97000: Restored neurons due to increased preservation loss.\n",
      "Step 98000: Restored neurons due to increased preservation loss.\n",
      "Step 99000: Restored neurons due to increased preservation loss.\n",
      "Step 100000: Restored neurons due to increased preservation loss.\n",
      "Step 100000, Training Loss: 2.313342571258545\n",
      "Step 101000: Restored neurons due to increased preservation loss.\n",
      "Step 102000: Restored neurons due to increased preservation loss.\n",
      "Step 103000: Restored neurons due to increased preservation loss.\n",
      "Step 104000: Restored neurons due to increased preservation loss.\n",
      "Step 105000: Restored neurons due to increased preservation loss.\n",
      "Step 106000: Restored neurons due to increased preservation loss.\n",
      "Step 107000: Restored neurons due to increased preservation loss.\n",
      "Step 108000: Restored neurons due to increased preservation loss.\n",
      "Step 109000: Restored neurons due to increased preservation loss.\n",
      "Step 110000: Restored neurons due to increased preservation loss.\n",
      "Step 110000, Training Loss: 2.392467498779297\n",
      "Step 111000: Restored neurons due to increased preservation loss.\n",
      "Step 112000: Restored neurons due to increased preservation loss.\n",
      "Step 113000: Restored neurons due to increased preservation loss.\n",
      "Step 114000: Restored neurons due to increased preservation loss.\n",
      "Step 115000: Restored neurons due to increased preservation loss.\n",
      "Step 116000: Restored neurons due to increased preservation loss.\n",
      "Step 117000: Restored neurons due to increased preservation loss.\n",
      "Step 118000: Restored neurons due to increased preservation loss.\n",
      "Step 119000: Restored neurons due to increased preservation loss.\n",
      "Step 120000: Restored neurons due to increased preservation loss.\n",
      "Step 120000, Training Loss: 1.8056193590164185\n",
      "Step 121000: Restored neurons due to increased preservation loss.\n",
      "Step 122000: Restored neurons due to increased preservation loss.\n",
      "Step 123000: Restored neurons due to increased preservation loss.\n",
      "Step 124000: Restored neurons due to increased preservation loss.\n",
      "Step 125000: Restored neurons due to increased preservation loss.\n",
      "Step 126000: Restored neurons due to increased preservation loss.\n",
      "Step 127000: Restored neurons due to increased preservation loss.\n",
      "Step 128000: Restored neurons due to increased preservation loss.\n",
      "Step 129000: Restored neurons due to increased preservation loss.\n",
      "Step 130000: Restored neurons due to increased preservation loss.\n",
      "Step 130000, Training Loss: 2.0000650882720947\n",
      "Step 131000: Restored neurons due to increased preservation loss.\n",
      "Step 132000: Restored neurons due to increased preservation loss.\n",
      "Step 133000: Restored neurons due to increased preservation loss.\n",
      "Step 134000: Restored neurons due to increased preservation loss.\n",
      "Step 135000: Restored neurons due to increased preservation loss.\n",
      "Step 136000: Restored neurons due to increased preservation loss.\n",
      "Step 137000: Restored neurons due to increased preservation loss.\n",
      "Step 138000: Restored neurons due to increased preservation loss.\n",
      "Step 139000: Restored neurons due to increased preservation loss.\n",
      "Step 140000: Restored neurons due to increased preservation loss.\n",
      "Step 140000, Training Loss: 2.1767499446868896\n",
      "Step 141000: Restored neurons due to increased preservation loss.\n",
      "Step 142000: Restored neurons due to increased preservation loss.\n",
      "Step 143000: Restored neurons due to increased preservation loss.\n",
      "Step 144000: Restored neurons due to increased preservation loss.\n",
      "Step 145000: Restored neurons due to increased preservation loss.\n",
      "Step 146000: Restored neurons due to increased preservation loss.\n",
      "Step 147000: Restored neurons due to increased preservation loss.\n",
      "Step 148000: Restored neurons due to increased preservation loss.\n",
      "Step 149000: Restored neurons due to increased preservation loss.\n",
      "Step 150000: Restored neurons due to increased preservation loss.\n",
      "Step 150000, Training Loss: 1.9481080770492554\n",
      "Step 151000: Restored neurons due to increased preservation loss.\n",
      "Step 152000: Restored neurons due to increased preservation loss.\n",
      "Step 153000: Restored neurons due to increased preservation loss.\n",
      "Step 154000: Restored neurons due to increased preservation loss.\n",
      "Step 155000: Restored neurons due to increased preservation loss.\n",
      "Step 156000: Restored neurons due to increased preservation loss.\n",
      "Step 157000: Restored neurons due to increased preservation loss.\n",
      "Step 158000: Restored neurons due to increased preservation loss.\n",
      "Step 159000: Restored neurons due to increased preservation loss.\n",
      "Step 160000: Restored neurons due to increased preservation loss.\n",
      "Step 160000, Training Loss: 2.4416146278381348\n",
      "Step 161000: Restored neurons due to increased preservation loss.\n",
      "Step 162000: Restored neurons due to increased preservation loss.\n",
      "Step 163000: Restored neurons due to increased preservation loss.\n",
      "Step 164000: Restored neurons due to increased preservation loss.\n",
      "Step 165000: Restored neurons due to increased preservation loss.\n",
      "Step 166000: Restored neurons due to increased preservation loss.\n",
      "Step 167000: Restored neurons due to increased preservation loss.\n",
      "Step 168000: Restored neurons due to increased preservation loss.\n",
      "Step 169000: Restored neurons due to increased preservation loss.\n",
      "Step 170000: Restored neurons due to increased preservation loss.\n",
      "Step 170000, Training Loss: 1.9113616943359375\n",
      "Step 171000: Restored neurons due to increased preservation loss.\n",
      "Step 172000: Restored neurons due to increased preservation loss.\n",
      "Step 173000: Restored neurons due to increased preservation loss.\n",
      "Step 174000: Restored neurons due to increased preservation loss.\n",
      "Step 175000: Restored neurons due to increased preservation loss.\n",
      "Step 176000: Restored neurons due to increased preservation loss.\n",
      "Step 177000: Restored neurons due to increased preservation loss.\n",
      "Step 178000: Restored neurons due to increased preservation loss.\n",
      "Step 179000: Restored neurons due to increased preservation loss.\n",
      "Step 180000: Restored neurons due to increased preservation loss.\n",
      "Step 180000, Training Loss: 2.357042074203491\n",
      "Step 181000: Restored neurons due to increased preservation loss.\n",
      "Step 182000: Restored neurons due to increased preservation loss.\n",
      "Step 183000: Restored neurons due to increased preservation loss.\n",
      "Step 184000: Restored neurons due to increased preservation loss.\n",
      "Step 185000: Restored neurons due to increased preservation loss.\n",
      "Step 186000: Restored neurons due to increased preservation loss.\n",
      "Step 187000: Restored neurons due to increased preservation loss.\n",
      "Step 188000: Restored neurons due to increased preservation loss.\n",
      "Step 189000: Restored neurons due to increased preservation loss.\n",
      "Step 190000: Restored neurons due to increased preservation loss.\n",
      "Step 190000, Training Loss: 2.319916248321533\n",
      "Step 191000: Restored neurons due to increased preservation loss.\n",
      "Step 192000: Restored neurons due to increased preservation loss.\n",
      "Step 193000: Restored neurons due to increased preservation loss.\n",
      "Step 194000: Restored neurons due to increased preservation loss.\n",
      "Step 195000: Restored neurons due to increased preservation loss.\n",
      "Step 196000: Restored neurons due to increased preservation loss.\n",
      "Step 197000: Restored neurons due to increased preservation loss.\n",
      "Step 198000: Restored neurons due to increased preservation loss.\n",
      "Step 199000: Restored neurons due to increased preservation loss.\n"
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "compression_rate = 0.1  # Compress 10% of neurons\n",
    "lossi = []\n",
    "stepi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # --- Training Phase ---\n",
    "    # Minibatch construction\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    X_batch, Y_batch = Xtr[ix], Ytr[ix]\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[X_batch]  # (batch_size, block_size, embedding_dim)\n",
    "    h = torch.tanh(emb.view(batch_size, -1) @ W1 + b1)  # (batch_size, hidden_neurons)\n",
    "    logits = h @ W2 + b2  # (batch_size, vocab_size)\n",
    "    loss = F.cross_entropy(logits, Y_batch)  # Training loss\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    lr = learning_rate if i < max_steps / 2 else learning_rate * 0.1  # Learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "    \n",
    "    # Track training loss\n",
    "    if i % 100 == 0:\n",
    "        lossi.append(loss.item())\n",
    "        stepi.append(i)\n",
    "    \n",
    "    # --- Preservation Set Evaluation ---\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        # Evaluate preservation set loss before compression\n",
    "        preservation_loss_before = evaluate_preservation_set(preservation_set, parameters)\n",
    "        \n",
    "        # Compress neurons\n",
    "        W1_backup, W2_backup, compressed_neurons_w1, compressed_neurons_w2 = compress_neurons(W1, W2, compression_rate)\n",
    "        \n",
    "        # Evaluate preservation set loss after compression\n",
    "        preservation_loss_after = evaluate_preservation_set(preservation_set, parameters)\n",
    "        \n",
    "        # Restore neurons if preservation loss increases\n",
    "        if preservation_loss_after > preservation_loss_before:\n",
    "            restore_neurons(W1, W2, W1_backup, W2_backup, compressed_neurons_w1, compressed_neurons_w2)\n",
    "            print(f\"Step {i}: Restored neurons due to increased preservation loss.\")\n",
    "        else:\n",
    "            print(f\"Step {i}: Neuron compression successful.\")\n",
    "    \n",
    "    # Print progress every 10000 steps\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Step {i}, Training Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(stepi, lossi)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss over Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.1581881046295166\n"
     ]
    }
   ],
   "source": [
    "def evaluate_test_set(X, Y, parameters):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    with torch.no_grad():\n",
    "        emb = C[X]\n",
    "        h = torch.tanh(emb.view(-1, W1.shape[0]) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y)\n",
    "    return loss.item()\n",
    "\n",
    "test_loss = evaluate_test_set(Xte, Yte, parameters)\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Names:\n",
      "Fran\n",
      "Izaan\n",
      "Dau\n",
      "Eianne\n",
      "Tilvin\n",
      "Geus\n",
      "Torahlona\n",
      "Brodisa\n",
      "Kateymani\n",
      "Jore\n"
     ]
    }
   ],
   "source": [
    "def sample_names(num_names, parameters, max_length=10):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    names = []\n",
    "    for _ in range(num_names):\n",
    "        context = [0] * block_size  # Start with context of zeros\n",
    "        name = ''\n",
    "        while True:\n",
    "            emb = C[torch.tensor([context])]\n",
    "            h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "            logits = h @ W2 + b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1).item()\n",
    "            char = itos[ix]\n",
    "            if char == '.':\n",
    "                break\n",
    "            name += char\n",
    "            context = context[1:] + [ix]\n",
    "            if len(name) >= max_length:\n",
    "                break\n",
    "        names.append(name)\n",
    "    return names\n",
    "\n",
    "generated_names = sample_names(10, parameters)\n",
    "print(\"Generated Names:\")\n",
    "for name in generated_names:\n",
    "    print(name.capitalize())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
