{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moe-Zbeeb/Safety-Driven-Self-Compressing-Neural-Networks/blob/main/exp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bmARt25PIh-",
        "outputId": "3cdcae4c-84c6-4061-cd08-a51f580dbfe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-51802d1aa368>:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  llm = ChatOpenAI(model=\"gpt-4o\")\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22bixjJCPIiC"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PsDe5dBzPIiD",
        "outputId": "13f7a272-ad0f-4dcc-bbac-997b0155982d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 63 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 99 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 117 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 139 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 146 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 155 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 170 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 176 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 178 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 189 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 198 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 206 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 226 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 236 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 248 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 267 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 280 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 289 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 300 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 310 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 323 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 331 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 345 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 356 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 364 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 371 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 384 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 393 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 415 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 430 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 438 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 453 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 461 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 469 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 476 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 487 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 502 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 509 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 518 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 526 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "American University of BeirutWater Pollution & Wastewater TreatmentEnvironmentalChemistry, vanLoon& Duffy –Chapter16Mohamad Hmadeh, PhDAssistant ProfessorDepartment of Chemistry, Room 424Ext. 4988 , E-mail: mohamad.hmadeh@aub.edu.lb\n"
          ]
        }
      ],
      "source": [
        "loader = PyPDFLoader(\"/content/Chapter+16+vanLoon+-+Water+Pollution+and+Waste-Water+Treatment-23 2.pdf\")\n",
        "\n",
        "# Load the document into Langchain\n",
        "docs = loader.load()\n",
        "\n",
        "# Test by printing the content or the first chunk of the document\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qd5GYiX3DWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "c_2MpKEPPIiG",
        "outputId": "d9beaaeb-095e-4a75-d55d-c947e4773a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='The chapter on water pollution and wastewater treatment from \"Environmental Chemistry\" by van Loon and Duffy, presented by Dr. Mohamad Hmadeh of the American University of Beirut, outlines key concepts and processes related to water pollution and treatment. Water pollution is defined as the presence of harmful chemicals or microorganisms above natural levels due to human activities, and pollutants are substances that adversely alter the environment. Criteria for distinguishing polluted from non-polluted water include physical, chemical, radiological, and microbiological properties.\\n\\nPoint sources of water pollutants are specific discharge points like factories, while nonpoint sources spread over larger areas, such as agricultural land. General types of water pollution include pathogens, oxygen-consuming agents, plant nutrients, toxic substances, dissolved solids, acids, suspended solids, oil, radioactive substances, and thermal pollution.\\n\\nBiological oxygen demand (BOD) measures the amount of oxygen needed to oxidize organic carbon in water, and high BOD can deplete dissolved oxygen (DO), harming aquatic life. Organic waste and excessive nutrients like nitrogen and phosphorus can lead to eutrophication, causing algae blooms and further oxygen depletion.\\n\\nWater treatment processes aim to remove pollutants to protect human health and aquatic ecosystems. Primary treatment involves screening and settling solids, secondary treatment uses bacteria to break down organic matter, and tertiary treatment removes nutrients and other pollutants through chemical and biological processes. Disinfection methods include chlorine, chlorine dioxide, and ozone, each with pros and cons. Home water softening often involves ion-exchange processes to remove hardness caused by calcium and magnesium. \\n\\nOverall, effective wastewater treatment is crucial for maintaining water quality and preventing environmental degradation.\\n\\n1. Water Pollution\\n2. Wastewater Treatment\\n3. Environmental Chemistry\\n4. Pollution Criteria\\n5. Water Quality Guidelines\\n6. Point Sources\\n7. Nonpoint Sources\\n8. Biological Oxygen Demand (BOD)\\n9. Oxygen-Consuming Agents\\n10. Eutrophication\\n11. Nitrogen and Phosphorus Sources\\n12. Primary Water Treatment\\n13. Secondary Water Treatment\\n14. Tertiary Water Treatment\\n15. Sludge Disposal')]\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result1 = chain.invoke({\"context\": docs})\n",
        "print(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sj7Qi46PPIiH",
        "outputId": "527f51b2-af74-4c53-8b3d-66963155ea93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Water Pollution\n",
            "2. Wastewater Treatment\n",
            "3. Environmental Chemistry\n",
            "4. Pollution Criteria\n",
            "5. Water Quality Guidelines\n",
            "6. Point Sources\n",
            "7. Nonpoint Sources\n",
            "8. Biological Oxygen Demand (BOD)\n",
            "9. Oxygen-Consuming Agents\n",
            "10. Eutrophication\n",
            "11. Nitrogen and Phosphorus Sources\n",
            "12. Primary Water Treatment\n",
            "13. Secondary Water Treatment\n",
            "14. Tertiary Water Treatment\n",
            "15. Sludge Disposal\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"Extract 10 to 15 keywords that summarizes key concepts in the doc:\\\\n\\\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result2 = chain.invoke({\"context\": docs})\n",
        "print(result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cjOD-9h8PIiI"
      },
      "outputs": [],
      "source": [
        "context = result1 + \"\\n\\n\" + result2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y50m8w3CPIiJ",
        "outputId": "5590cc0b-6ab8-47a6-f1f1-e9fe56d651d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "type(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0CLFBUrAPIiK",
        "outputId": "0ccc52a7-6aa2-41cc-963a-88be5f7216da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are 8 multiple-choice questions (MCQs) based on the chapter summary:\n",
            "\n",
            "1. **What is water pollution?**\n",
            "   - A) The natural presence of chemicals in water\n",
            "   - B) The presence of harmful chemicals or microorganisms above natural levels due to human activities\n",
            "   - C) The accumulation of beneficial substances in water\n",
            "   - D) The excess growth of aquatic plants\n",
            "\n",
            "2. **Which of the following is a point source of water pollution?**\n",
            "   - A) Agricultural runoff\n",
            "   - B) Urban stormwater\n",
            "   - C) A factory discharge pipe\n",
            "   - D) Atmospheric deposition\n",
            "\n",
            "3. **What does Biological Oxygen Demand (BOD) measure?**\n",
            "   - A) The amount of dissolved oxygen in water\n",
            "   - B) The oxygen required to oxidize organic carbon in water\n",
            "   - C) The concentration of pathogens in water\n",
            "   - D) The temperature of water\n",
            "\n",
            "4. **What is eutrophication primarily caused by?**\n",
            "   - A) High levels of dissolved oxygen\n",
            "   - B) Excessive nutrients like nitrogen and phosphorus\n",
            "   - C) Low Biological Oxygen Demand (BOD)\n",
            "   - D) High levels of heavy metals\n",
            "\n",
            "5. **What is the main goal of primary water treatment?**\n",
            "   - A) To remove dissolved nutrients\n",
            "   - B) To disinfect water\n",
            "   - C) To screen and settle large solids\n",
            "   - D) To break down organic matter using bacteria\n",
            "\n",
            "6. **Which disinfection method involves the use of a gas that can be hazardous if not handled properly?**\n",
            "   - A) Chlorine\n",
            "   - B) Ozone\n",
            "   - C) UV radiation\n",
            "   - D) Boiling\n",
            "\n",
            "7. **Which process is often used in home water softening?**\n",
            "   - A) Filtration\n",
            "   - B) Ion-exchange\n",
            "   - C) Reverse osmosis\n",
            "   - D) Distillation\n",
            "\n",
            "8. **What is the primary objective of tertiary water treatment?**\n",
            "   - A) To remove large solids\n",
            "   - B) To break down organic matter\n",
            "   - C) To remove nutrients and other pollutants through chemical and biological processes\n",
            "   - D) To disinfect water using chlorine\n",
            "\n",
            "**Answers:**\n",
            "1. B) The presence of harmful chemicals or microorganisms above natural levels due to human activities\n",
            "2. C) A factory discharge pipe\n",
            "3. B) The oxygen required to oxidize organic carbon in water\n",
            "4. B) Excessive nutrients like nitrogen and phosphorus\n",
            "5. C) To screen and settle large solids\n",
            "6. A) Chlorine\n",
            "7. B) Ion-exchange\n",
            "8. C) To remove nutrients and other pollutants through chemical and biological processes\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"Based on the summary:\\n\\n{context}, create an 8-question quiz that tests the reader's understanding of the document make the questions MCQ.\")]\n",
        ")\n",
        "\n",
        "# Instantiate the chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Check if context is a list\n",
        "if isinstance(context, list):\n",
        "    # Ensure each element in the list is a string and convert them to Document objects\n",
        "    docs = [Document(page_content=item) for item in context]\n",
        "else:\n",
        "    # If context is not a list, convert it to a single Document\n",
        "    docs = [Document(page_content=str(context))]\n",
        "\n",
        "# Invoke the chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "\n",
        "# Print the result\n",
        "#write to file\n",
        "with open('quiz1.md', 'w') as f:\n",
        "    f.write(result)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rrVqpxKjPIiL",
        "outputId": "d21f9ea6-3188-48e1-8d5f-a1e4bf935921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "context += \"\\n\\n\" + \"QUESTIONS\"+ '\\n' + result\n",
        "print(type(context))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "djmou3ZAPIiN",
        "outputId": "a44b6fa4-5015-4781-a752-117921389985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "1. B\n",
            "2. C\n",
            "3. B\n",
            "4. B\n",
            "5. C\n",
            "6. A\n",
            "7. B\n",
            "8. C\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Define prompt for the chain\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Based on the following summary: {context} and the quiz questions: {{result}}, answer each of the following questions concisely and return only the answers.\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Instantiate chain with the defined prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Check and convert the context to a Document object\n",
        "if isinstance(context, list):\n",
        "    # If context is a list, join its elements into a single string and create a Document\n",
        "    context = \" \".join(context)  # Combine list into a single string\n",
        "context_doc = Document(page_content=context)  # Wrap the context in a Document\n",
        "\n",
        "# Print the type to ensure it is now a Document\n",
        "print(type(context_doc))  # This should print: <class 'langchain.schema.Document'>\n",
        "\n",
        "# Invoke chain with the context now wrapped in a Document object\n",
        "answers = chain.invoke({\"context\": [context_doc]})  # Pass as a list of Document objects\n",
        "\n",
        "# Print the generated answers\n",
        "print(answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QZrCUOHZPIiO",
        "outputId": "51c45b85-f89f-4dc0-a62e-d4efc112198c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. B\\n2. C\\n3. B\\n4. B\\n5. C\\n6. A\\n7. B\\n8. C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "othGR8DCPIiP",
        "outputId": "ff86bfcd-a54c-44d8-8838-4326617a7e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1. B', '2. C', '3. B', '4. B', '5. C', '6. A', '7. B', '8. C']\n"
          ]
        }
      ],
      "source": [
        "#make the string as 1d list\n",
        "answers = answers.split(\"\\n\")\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sUfpzoktPIiP",
        "outputId": "1abcd921-7c9a-4d64-e078-f28d95e3a025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B\n",
            "C\n",
            "B\n",
            "B\n",
            "C\n",
            "A\n",
            "B\n",
            "C\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(answers)):\n",
        "    answers[i] = answers[i][3]\n",
        "    print(answers[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ekpKC6XGPIiQ",
        "outputId": "c49d5f77-961d-4667-d359-f3a7136123a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B', 'C', 'B', 'B', 'C', 'A', 'B', 'C']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FE0SOitJPIiR",
        "outputId": "87ca692b-18eb-4d01-f193-5d02dd9ac7e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "inputuser = ['A', 'C', 'B', 'B', 'C', 'A', 'B', 'C']\n",
        "\n",
        "#grader\n",
        "def grade(answers, inputuser):\n",
        "    wrongs = []\n",
        "    score = 0\n",
        "    for i in range(len(answers)):\n",
        "        if answers[i] != inputuser[i]:\n",
        "            wrongs.append(i)\n",
        "    return wrongs\n",
        "print(grade(answers, inputuser))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RIdGU4CTPIiS",
        "outputId": "0b1a3f86-c3d8-4cd7-8175-9d848a19fda4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "Sure! Here are two additional questions to further assess the student's understanding of the topics where mistakes were made:\n",
            "\n",
            "**Additional Questions:**\n",
            "\n",
            "1. **What are the criteria used to distinguish polluted water from non-polluted water?**\n",
            "   - A) Only chemical properties\n",
            "   - B) Only physical properties\n",
            "   - C) Physical, chemical, radiological, and microbiological properties\n",
            "   - D) Only microbiological properties\n",
            "\n",
            "2. **Which of the following is NOT a general type of water pollution?**\n",
            "   - A) Pathogens\n",
            "   - B) Dissolved solids\n",
            "   - C) Heavy metals\n",
            "   - D) Thermal pollution\n",
            "\n",
            "**Answers:**\n",
            "1. C) Physical, chemical, radiological, and microbiological properties\n",
            "2. C) Heavy metals\n"
          ]
        }
      ],
      "source": [
        "# Get the wrong answers indices from grade\n",
        "wrongs = grade(answers, inputuser)  # e.g., [1, 2]\n",
        "\n",
        "# Update context with wrong answers information\n",
        "context = context + '\\n' + \"WRONG ANSWERS\\n\" + str(wrongs)  # Add wrong answers info to context\n",
        "\n",
        "# Define prompt for generating new questions based on wrong answers\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Based on the following details: {context} and the quiz questions, \"\n",
        "                   \"the user made mistakes in the questions with indices {wrongs}. Create additional questions \"\n",
        "                   \"in the same style to assess the student further on the topics they struggled with.\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Instantiate chain with the defined prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Convert context to a Document object if necessary\n",
        "if isinstance(context, list):\n",
        "    context = \" \".join(context)  # If context is a list, combine it into a single string\n",
        "context_doc = Document(page_content=context)  # Wrap the context in a Document object\n",
        "\n",
        "# Print the type to ensure it is now a Document\n",
        "print(type(context_doc))  # This should print: <class 'langchain.schema.Document'>\n",
        "\n",
        "# Invoke chain with the context now wrapped in a Document object\n",
        "questions2 = chain.invoke({\"context\": [context_doc], \"result\": context_doc, \"wrongs\": str(wrongs)})  # Pass context, result, and wrongs\n",
        "\n",
        "# Print the generated answers\n",
        "#write to file\n",
        "with open('quiz2.md', 'w') as f:\n",
        "    f.write(questions2)\n",
        "print(questions2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9bQ8Aju9PIiS",
        "outputId": "a9367cc0-8df9-419f-bf86-9c50a10ce475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "1. C\n",
            "2. C\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Combine context with additional questions\n",
        "new_context = context + '\\n' + \"QUESTIONS2\\n\" + questions2\n",
        "\n",
        "# Define the prompt to return only the letter corresponding to the correct answer\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Based on the following summary: {context}, answer each of the following questions under the section 'QUESTIONS2'. \"\n",
        "                   \"Return only the letter of the correct answer (A, B, C, or D) with no additional information.\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Instantiate the chain with the defined prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Ensure context is a string before wrapping it in Document\n",
        "if isinstance(new_context, list):\n",
        "    new_context = \" \".join(new_context)  # Convert list to a single string\n",
        "\n",
        "# Wrap the new context in a Document object\n",
        "new_context_doc = Document(page_content=new_context)  # Wrap the new context in a Document\n",
        "\n",
        "# Print the type to ensure it is now a Document\n",
        "print(type(new_context_doc))  # This should print: <class 'langchain.schema.Document'>\n",
        "\n",
        "# Invoke the chain with the new context now wrapped in a Document object\n",
        "answers = chain.invoke({\"context\": [new_context_doc]})  # Pass as a list of Document objects\n",
        "\n",
        "# Print the generated answers (it should return only the alphabet of the answer)\n",
        "print(answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QTLbSfKPIiT",
        "outputId": "31fa598f-a3c6-4d85-d61e-63e1c1368953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1. B', '2. B', '3. B', '4. B', '5. B', '6. B']\n"
          ]
        }
      ],
      "source": [
        "#make the string as 1d list\n",
        "answers = answers.split(\"\\n\")\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJHqwXyAPIiU",
        "outputId": "07fed19f-3ae1-4331-af70-d0bc8e3e129d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5]\n"
          ]
        }
      ],
      "source": [
        "inputuser = ['b', 'c', 'b', 'c', 'b', 'c', 'b', 'b']\n",
        "\n",
        "#grader\n",
        "def grade(answers, inputuser):\n",
        "    wrongs = []\n",
        "    score = 0\n",
        "    for i in range(len(answers)):\n",
        "        if answers[i] != inputuser[i]:\n",
        "            wrongs.append(i)\n",
        "    return wrongs\n",
        "print(grade(answers, inputuser))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_context = new_context + '\\n' + \"WRONG ANSWERS\\n\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Based on the following details: {context}, Your task is to assess the my knowledge based on my answers. \"\n",
        "                   \"In your evaluation report, please include the following:\"\n",
        "                   \"Identify any topics where the I seem confused or mixing concepts.\"\n",
        "                   \"Highlight the areas where the I demonstrated strong understanding.\"\n",
        "                   \"Point out any areas where the I showed weaknesses or lacks knowledge\")\n",
        "\n",
        "    ]\n",
        ")\n",
        "# Step 4: Instantiate chain with the defined prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Step 5: Convert the complete context to a Document object\n",
        "Assesment_doc = Document(page_content=complete_context)\n",
        "\n",
        "# Print the type to ensure it is now a Document\n",
        "print(type(Assesment_doc))  # This should print: <class 'langchain.schema.Document'>\n",
        "\n",
        "# Step 6: Invoke chain to generate Final Assesment\n",
        "Assesment = chain.invoke({\"context\": [Assesment_doc]})\n",
        "print(\"Final Assesment\", Assesment)\n",
        "with open(\"Final_Assesment.md\", \"w\") as file:\n",
        "    file.write(Assesment)\n",
        "    file.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gJoHl8rHZAy",
        "outputId": "ab6d50ef-7df9-4dca-f2f3-3baaed63364d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "Final Assesment ### Evaluation Report\n",
            "\n",
            "#### Areas of Strong Understanding\n",
            "\n",
            "1. **Definition of Water Pollution:** \n",
            "   - You correctly identified water pollution as the presence of harmful chemicals or microorganisms above natural levels due to human activities.\n",
            "   \n",
            "2. **Point Source of Water Pollution:**\n",
            "   - You correctly recognized a factory discharge pipe as a point source of water pollution.\n",
            "\n",
            "3. **Biological Oxygen Demand (BOD):**\n",
            "   - You accurately understood that BOD measures the oxygen required to oxidize organic carbon in water.\n",
            "\n",
            "4. **Eutrophication:**\n",
            "   - You correctly identified that eutrophication is primarily caused by excessive nutrients like nitrogen and phosphorus.\n",
            "\n",
            "5. **Disinfection Method:**\n",
            "   - You correctly identified that chlorine is a disinfection method that involves the use of a potentially hazardous gas.\n",
            "\n",
            "6. **Home Water Softening:**\n",
            "   - You correctly recognized ion-exchange as a common process used in home water softening.\n",
            "\n",
            "7. **Tertiary Water Treatment:**\n",
            "   - You correctly understood that the primary objective of tertiary water treatment is to remove nutrients and other pollutants through chemical and biological processes.\n",
            "\n",
            "#### Areas of Confusion or Mixed Concepts\n",
            "\n",
            "1. **Primary Water Treatment:**\n",
            "   - You incorrectly identified the main goal of primary water treatment. The correct answer is to screen and settle large solids (Answer: C), but you selected an incorrect option.\n",
            "\n",
            "#### Areas of Weakness or Lack of Knowledge\n",
            "\n",
            "1. **Criteria for Distinguishing Polluted Water:**\n",
            "   - You made an error in identifying the criteria used to distinguish polluted water from non-polluted water. The correct answer includes physical, chemical, radiological, and microbiological properties (Answer: C).\n",
            "\n",
            "2. **General Types of Water Pollution:**\n",
            "   - You incorrectly answered which of the following is not a general type of water pollution. Heavy metals are indeed a significant type of water pollution, while the correct answer should have been a different option.\n",
            "\n",
            "### Recommendations\n",
            "\n",
            "1. **Review Primary Water Treatment:**\n",
            "   - Revisit the primary water treatment process to understand its main goal, which is to screen and settle large solids. This will help clarify the initial steps in water treatment and their purposes.\n",
            "\n",
            "2. **Understand Pollution Criteria:**\n",
            "   - Study the criteria used to distinguish polluted water from non-polluted water in more depth. Focus on the physical, chemical, radiological, and microbiological properties.\n",
            "\n",
            "3. **General Types of Water Pollution:**\n",
            "   - Ensure you have a comprehensive understanding of all general types of water pollution, including pathogens, dissolved solids, heavy metals, and thermal pollution, so you can accurately identify them.\n",
            "\n",
            "By focusing on these areas, you can strengthen your overall understanding of water pollution and wastewater treatment processes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXvAtkKsPIiV",
        "outputId": "700efed1-35c3-4b75-fa47-ee6a036ec808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "Generated Study Material:\n",
            " ### Flashcards\n",
            "\n",
            "1. **Question:** What is the primary objective of the method proposed in \"Safety Driven Self Compressing Neural Networks\"?\n",
            "   **Answer:** To reduce the size of neural networks by eliminating redundant weights and minimizing bit depth.\n",
            "\n",
            "2. **Question:** How does the proposed method maintain floating-point accuracy while reducing model size?\n",
            "   **Answer:** By using a fully differentiable quantization function and the Straight-Through Estimator (STE).\n",
            "\n",
            "3. **Question:** What are the key advantages of the proposed method?\n",
            "   **Answer:** Fewer weights, efficient bit usage, faster training and execution, and a simplified design process.\n",
            "\n",
            "4. **Question:** Why does the proposed method group weights by channel?\n",
            "   **Answer:** To enhance stability and avoid forgetting important features.\n",
            "\n",
            "5. **Question:** What role does the custom loss function play in the proposed method?\n",
            "   **Answer:** It balances task accuracy with network size.\n",
            "\n",
            "6. **Question:** What differentiates this method from previous methods that required specialized operators and hardware?\n",
            "   **Answer:** It uses a fully differentiable quantization function and the basic Straight-Through Estimator (STE) for training.\n",
            "\n",
            "7. **Question:** How does the method ensure that exponents and bit depths are optimized during training?\n",
            "   **Answer:** By making exponents and bit depths trainable parameters.\n",
            "\n",
            "8. **Question:** What does the feature-preserving algorithm aim to prevent during the compression process?\n",
            "   **Answer:** Irreversible forgetting of important features.\n",
            "\n",
            "9. **Question:** How does the proposed method differ from approaches that require specialized hardware?\n",
            "   **Answer:** It employs a fully differentiable quantization function and the basic Straight-Through Estimator (STE) for training.\n",
            "\n",
            "10. **Question:** What is one of the main reasons why the proposed method eliminates redundant weights?\n",
            "    **Answer:** To reduce the computational and memory requirements during training and inference.\n",
            "\n",
            "11. **Question:** Which of the following is a key advantage of the proposed method in terms of training and execution?\n",
            "    **Answer:** It achieves faster training and execution times.\n",
            "\n",
            "12. **Question:** Why is it important for the exponents and bit depths to be trainable parameters in the proposed method?\n",
            "    **Answer:** To enable automatic optimization during the training process.\n",
            "\n",
            "13. **Question:** What mechanism does the proposed method use to prevent irreversible forgetting of important features during compression?\n",
            "    **Answer:** By employing a feature-preserving algorithm that maintains essential features.\n",
            "\n",
            "14. **Question:** What is Quantization-Aware Training (QAT)?\n",
            "    **Answer:** A technique that incorporates quantization into the training process to improve the performance of quantized models.\n",
            "\n",
            "15. **Question:** What is the Straight-Through Estimator (STE)?\n",
            "    **Answer:** An estimator used to approximate gradients for non-differentiable functions during backpropagation.\n",
            "\n",
            "16. **Question:** What does induced network sparsity refer to?\n",
            "    **Answer:** The deliberate reduction of weights in a neural network to create a sparse model.\n",
            "\n",
            "17. **Question:** What is structured sparsity?\n",
            "    **Answer:** A form of sparsity where entire structures, such as channels or layers, are pruned or removed.\n",
            "\n",
            "18. **Question:** What is channel pruning?\n",
            "    **Answer:** The process of removing entire channels from a neural network to reduce its size and complexity.\n",
            "\n",
            "19. **Question:** What is rounding in the context of neural network quantization?\n",
            "    **Answer:** The process of reducing the precision of weights by rounding them to the nearest quantized value.\n",
            "\n",
            "20. **Question:** What is the significance of bit depth in neural network quantization?\n",
            "    **Answer:** Bit depth determines the precision of the quantized weights and impacts the model's accuracy and size.\n",
            "\n",
            "### Summary of Key Topics\n",
            "\n",
            "The paper \"Safety Driven Self Compressing Neural Networks\" by Mohammad Zbeeb introduces a method to reduce neural network size by removing redundant weights and optimizing bit depth. This approach maintains floating-point accuracy and achieves efficient training and inference without specialized hardware. Key features include the use of a fully differentiable quantization function, the Straight-Through Estimator (STE), and a custom loss function that balances task accuracy with network size. The method also employs a feature-preserving algorithm to avoid forgetting important features during compression.\n",
            "\n",
            "### Study Plan\n",
            "\n",
            "#### Day 1: Understanding Core Concepts\n",
            "- **Morning:** Review the primary objective of the method and its key advantages.\n",
            "- **Afternoon:** Study the use of fully differentiable quantization functions and the Straight-Through Estimator (STE).\n",
            "- **Evening:** Go through the importance of grouping weights by channel and the custom loss function.\n",
            "\n",
            "#### Day 2: Technical Details and Mechanisms\n",
            "- **Morning:** Delve into the optimization of exponents and bit depths as trainable parameters.\n",
            "- **Afternoon:** Understand the feature-preserving algorithm and its role in preventing irreversible forgetting.\n",
            "- **Evening:** Review the concepts of induced network sparsity, structured sparsity, and channel pruning.\n",
            "\n",
            "#### Day 3: Application and Review\n",
            "- **Morning:** Practice flashcards focusing on key advantages, differentiability, and quantization functions.\n",
            "- **Afternoon:** Solve practice questions related to efficient training, inference, and the role of custom loss functions.\n",
            "- **Evening:** Conduct a self-assessment quiz to identify any weak areas.\n",
            "\n",
            "#### Day 4: Focus on Weak Areas\n",
            "- **Morning:** Revisit any concepts that were challenging, such as the role of STE and the feature-preserving algorithm.\n",
            "- **Afternoon:** Engage in discussions or study groups to clarify doubts and reinforce understanding.\n",
            "- **Evening:** Take another self-assessment quiz to ensure all concepts are clear.\n",
            "\n",
            "#### Day 5: Final Review and Practice\n",
            "- **Morning:** Go through all flashcards and ensure you can answer each question confidently.\n",
            "- **Afternoon:** Review the summary of key topics and practice explaining them in your own words.\n",
            "- **Evening:** Take a comprehensive practice exam covering all key areas to ensure readiness for the actual exam.\n",
            "\n",
            "This study plan should help you focus on key areas where improvement is needed and ensure a thorough understanding of the concepts presented in the paper. Good luck!\n"
          ]
        }
      ],
      "source": [
        "complete_context = new_context + '\\n' + \"WRONG ANSWERS\\n\"\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Based on the following details: {context}, generate 10 to 20 flashcards in the format of 'Question: Answer:', \"\n",
        "                   \"a small summary of the key topics (5-10 lines), and a study plan to exit the exam successfully. \"\n",
        "                   \"The study plan should prioritize key areas where the student needs improvement and help them focus efficiently.\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 4: Instantiate chain with the defined prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Step 5: Convert the complete context to a Document object\n",
        "complete_context_doc = Document(page_content=complete_context)\n",
        "\n",
        "# Print the type to ensure it is now a Document\n",
        "print(type(complete_context_doc))  # This should print: <class 'langchain.schema.Document'>\n",
        "\n",
        "# Step 6: Invoke chain to generate flashcards, summary, and study plan\n",
        "study_material = chain.invoke({\"context\": [complete_context_doc]})\n",
        "\n",
        "# Step 7: Print the generated flashcards, summary, and study plan\n",
        "print(\"Generated Study Material:\\n\", study_material)\n",
        "#write the study plan to a file\n",
        "with open(\"study_plan.md\", \"w\") as file:\n",
        "    file.write(study_material)\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ-BhK5SPIiV",
        "outputId": "df051467-9244-41f7-9626-aa3ff6f3a273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "Generated Study Material:\n",
            " The paper \"Safety Driven Self Compressing Neural Networks\" by Mohammad Zbeeb introduces a novel method for reducing the size of neural networks while maintaining their accuracy and performance. This method focuses on eliminating redundant weights and minimizing the bit depth required to represent the remaining weights. Here is a detailed summary highlighting the critical topics and concepts:\n",
            "\n",
            "### 1. Core Principles and Definitions\n",
            "\n",
            "**Neural Network Size Reduction**:\n",
            "- **Definition**: The process of decreasing the number of parameters (weights) in a neural network to make it smaller and more efficient.\n",
            "- **Importance**: Smaller neural networks require less computational power and memory, making them suitable for deployment in resource-constrained environments such as mobile devices and edge computing.\n",
            "\n",
            "**Redundant Weights**:\n",
            "- **Definition**: Weights in a neural network that do not significantly contribute to the model's performance. These can be pruned without substantially affecting the accuracy.\n",
            "- **Importance**: Identifying and eliminating redundant weights helps in reducing the model size and computational requirements.\n",
            "\n",
            "**Bit Depth**:\n",
            "- **Definition**: The number of bits used to represent each weight in a neural network.\n",
            "- **Importance**: Lowering bit depth reduces the memory footprint and can speed up computations if done correctly without losing precision.\n",
            "\n",
            "### 2. Key Methodologies and Models\n",
            "\n",
            "**Fully Differentiable Quantization Function**:\n",
            "- **Explanation**: A mathematical function used to convert floating-point weights to lower bit-depth representations while allowing gradients to flow through during training.\n",
            "- **Step-by-Step Reasoning**:\n",
            "  1. **Quantization**: Convert weights to a lower precision format.\n",
            "  2. **Differentiability**: Ensure that the quantization process is smooth enough to allow gradient-based optimization.\n",
            "  3. **Optimization**: Train the network end-to-end with these quantized weights to maintain performance.\n",
            "- **Application**: This approach allows optimizing both the weights and their representations during training, leading to efficient compression.\n",
            "\n",
            "**Straight-Through Estimator (STE)**:\n",
            "- **Explanation**: An approximation method used in training quantized neural networks where the gradient of the quantization function is approximated by the identity function.\n",
            "- **Step-by-Step Reasoning**:\n",
            "  1. **Forward Pass**: Apply quantization to the weights.\n",
            "  2. **Backward Pass**: Use STE to approximate the gradient of the non-differentiable quantization function.\n",
            "- **Application**: Enables effective training of quantized networks without the need for specialized hardware.\n",
            "\n",
            "**Custom Loss Function**:\n",
            "- **Explanation**: A loss function designed to balance the trade-off between task accuracy and network size.\n",
            "- **Components**:\n",
            "  1. **Task Accuracy Term**: Measures how well the network performs on the given task.\n",
            "  2. **Size Penalty Term**: Penalizes larger models to encourage weight reduction.\n",
            "- **Application**: Guides the training process to achieve a compact model without sacrificing accuracy.\n",
            "\n",
            "### 3. Grouping Weights by Channel\n",
            "\n",
            "**Purpose**:\n",
            "- **Enhance Stability**: Grouping weights by channel helps in maintaining the integrity of important features during compression.\n",
            "- **Avoid Forgetting**: Ensures that critical features are preserved, reducing the risk of performance degradation.\n",
            "\n",
            "### 4. Real-World Applications\n",
            "\n",
            "- **Mobile Devices**: Efficient neural networks can be deployed on smartphones and tablets where computational resources are limited.\n",
            "- **Edge Computing**: Smaller models can run on edge devices, reducing the need for data transfer to centralized servers and thus improving latency.\n",
            "- **IoT Devices**: Internet of Things devices can benefit from compact models to perform intelligent tasks without relying on cloud resources.\n",
            "\n",
            "### 5. Common Mistakes and Tips\n",
            "\n",
            "**Mistake 1: Over-Pruning**:\n",
            "- **Explanation**: Removing too many weights can lead to significant loss of accuracy.\n",
            "- **Tip**: Use the custom loss function to find the right balance between size reduction and accuracy.\n",
            "\n",
            "**Mistake 2: Ignoring Bit Depth Optimization**:\n",
            "- **Explanation**: Not optimizing bit depth can result in either loss of precision or unnecessary use of memory.\n",
            "- **Tip**: Ensure that both the exponents and bit depths are optimized as trainable parameters.\n",
            "\n",
            "**Mistake 3: Not Preserving Important Features**:\n",
            "- **Explanation**: Compressing the model without considering feature importance can lead to irreversible forgetting.\n",
            "- **Tip**: Use the feature-preserving algorithm to maintain essential features during compression.\n",
            "\n",
            "### 6. Logical Structure and Clarity\n",
            "\n",
            "The summary is structured to first introduce the core principles and definitions, providing a strong foundation for understanding the methodologies. Next, it explains the key models and how they function, followed by practical applications to illustrate the real-world impact. Finally, common mistakes are analyzed with tips to avoid them, ensuring a comprehensive understanding of the subject matter.\n",
            "\n",
            "By focusing on these critical topics and concepts, students can better prepare for exams and apply these principles effectively in both academic and practical scenarios.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Step 1: Define a more powerful prompt template with detailed instructions\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"Take the following study material {context} and summarize it in 100-150 lines, highlighting only the most critical topics and concepts to ensure exam success. Focus on the following:\n",
        "\n",
        "1. Comprehensive explanations of definitions and core principles. Expand on why they are important.\n",
        "2. In-depth explanation of key formulas, equations, or models, with step-by-step reasoning and how they apply in problem-solving.\n",
        "3. Diagrams or visual representations should be described in a way that helps retain crucial concepts.\n",
        "4. Analyze common mistakes students make and provide tips on how to avoid them.\n",
        "5. Provide detailed real-world applications or examples for each core concept.\n",
        "6. Structure the summary logically, ensuring it is easy to follow.\n",
        "\n",
        "Make the return elaborated where you explain details and notations in a well manner approach\n",
        "Be sure to elaborate on each point and ensure clarity. Keep the response length between 100 to 150 lines. The summary should be highly detailed, professional, and suitable for advanced exam preparation.\"\"\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 2: Instantiate the chain with the more powerful prompt\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Step 3: Convert the complete context to a Document object\n",
        "complete_context_doc = Document(page_content=complete_context)\n",
        "\n",
        "# Verify that it's a Document object\n",
        "print(type(complete_context_doc))  # Should print <class 'langchain.schema.Document'>\n",
        "\n",
        "# Step 4: Invoke the chain to generate in-depth study material\n",
        "study_material2 = chain.invoke({\"context\": [complete_context_doc]})\n",
        "\n",
        "# Step 5: Print the generated study material (flashcards, summary, and study plan)\n",
        "print(\"Generated Study Material:\\n\", study_material2)\n",
        "\n",
        "# Step 6: Write the study material to a markdown file\n",
        "with open(\"study_plan2.md\", \"w\") as file:\n",
        "    file.write(study_material2)  # Save generated material in study_plan2.md\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "startup",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}